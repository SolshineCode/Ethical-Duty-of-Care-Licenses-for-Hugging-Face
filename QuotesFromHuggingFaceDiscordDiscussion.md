# The following are quotes from the ongoing discussions on Hugging Face Discord server.
This discussion contributes to the ongoing development of these frameworks.
Please feel free to add additional quotes or contributions via PR.

Vipitis Stated:
```
my point is:
- the HL3 license seems really vague and many of it's extensions way to broad. Relying on a paid 3rd party ranking to know if you and your company is implicated seems bad. the result is: nobody really feels comfortable with a programm or some source code under this license. I certainly won't.
- it's not a fit for any projects that I am invovled with. I contribute to open source as that is much more helpful for people than closed projects they can't trust or debug themselves. I use and rely on a lot of other open source projects - and they can really only proliferate under a properly free license. Usage restrictions (if upheld) make lot's of projects inaccessible and are therefore avoided.
- I don't believe it will be included in the shorthand on the HF Hub because it's not widely used and there is already too many licenses today.
- open source might cause eventual harm to some - but so could any other software. You waive any warranties and liabilities. That is the whole idea.
"you can do what you want, but no guarantees". Usage restrictions are a negative freedom "we know what's good for you". 
- on the topic of langauge models, we have seen that properly open sourced projects/models/libraries/datasets proliferate. Therefore we should continue.
- there is no global moral compass, and therefore we can't come up with ethical guidelines that make everyone happy. Just give them the freedom instead. This includes the freedom to do harm.
- licenses don't feel like the appropriate tool to prosecute really horrible crimes. Maybe they are when you live in California - I don't.
```
CalebSol replied:
```
I've already enumerated this, but again point by point:
* Vagueness of HL3 license: You raise a valid point about one specific optional clause in the HL3. License terms should be clear and actionable. This issue can be addressed through further refinement and clarity in the license language.

* Incompatibility with open source ethos: Ethical duty-of-care licenses can be seen as an extension of open source values, promoting accountability and responsible development. Just as some may not use ethical duty-of-care licensed works; Many creators may not contribute to open source at all without their ethical concerns being addressed.

* Widespread adoption: Widespread short-term adoption may be challenging, but the long-term impact of these licenses could be significant in addressing real concerns by creators.

* Inherent software risks: Ethical duty-of-care licenses can be a valuable tool in mitigating risks and promoting responsible practices, even if they don't eliminate all potential for harm.

* Open source and language models: I strongly agree that the open and collaborative approach should continue, but ethical considerations should be integrated into this process. Technology has real world effects. Ignoring this is unhealthy for world-wide cooperation, ie via marginalization. Taking responsibility for this is ultimately healthy for the open source ecosystem.

* Lack of global moral compass: Ethical duty-of-care licenses can be a pragmatic approach within specific contexts, even if a universal ethical framework remains elusive.

* Licenses and crime prosecution: I agree that licenses may not be the best tool for directly prosecuting crimes, but they can promote a culture of ethical awareness and open up avenues of citizen enforcement.

Overall, while challenges exist, open source ethical duty-of-care licenses have the potential to be beneficial for the open source ecosystem by taking responsibility for the consequences of our actions and addressing marginalization.
```
----
Faramith stated:
```
<@714682004721106965> I also want to mention that this concept is really useful to make AI Ethics an actual thing by enforcing it through licenses
```

----

TeaDaniels stated:
```
<@714682004721106965> 
Need all the points about litigation done as a state chart. ðŸ¤£
```

----

Faramith stated:
```
Sure there could be licenses that could enforce "best practices" as in "ethical practices" maybe but that needs to be defined well: why would someone who is within a country that has an AI law (AI Act) would care about ethics as long as he follows the law?
```

CalebSol replied:
```
Because:
(1) the developers of the technology wish to only allow it's use publicly within the ethical parameters defined in a way they agree. This is quintessential to the nature of licenses: they define the intention of the rights holder(s)  in how the innovation can be used by others, expressing their freedom to define their rights. This is especially appealing to developers who have personal or demographic experience of being marginalized or colonized.
(2) The ability for developers to define their own terms of public engagement with their technology encourages open sourcing of technologies which may have otherwise not been made open source, either due to the identification with marginalized personal/demographic experiences or other ethical concerns of the developers. This is good for the open source ecosystem and development of the sciences as a whole, bringing in more contributors.
(3) Allowing for community use and opening source, while barring mis-use, creates an avenue to enforceably condifying personal ethical concern in a personalized manner. These licenses thereby address the recurring debate around unifying ethics or expressing diverse ethics in how AI/ML technology is used.
(4) Regulatory bodies often do not express all possible ethical considerations relevant to developers. Further, in cases where they do account for ethical consideration, the history of enforcement shows it to be often lacking in timeliness, resources, and regulator initiative, even extending to regulatory capture. The enforcement of IP licenses overcomes those shortcomings using an approach available to the community as a whole.
(5) IP litigation has historically been a more effective channel to stopping IP misuse, as compared to regulatory enforcement.
```
undeleted replied
```
I continue dispute the idea that model weights are copyrightable and thus can be subject to licensing, which would render the whole premise moot.

Other than that, I oppose the practice because I oppose private enforcement of social norms or public policy, since private entities are not accountable to anyone but themselves. Governments and regulatory bodies in most modern, democratic countries are at least indirectly accountable to the people.

Also, open source and free software must not have use restrictions by definition. It's fine if a license wants to impose those, but it should not claim to be open source or free software, as this is misleading (and ironically enough, unethical).
```

